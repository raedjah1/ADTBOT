"""
AI-Powered Vulnerability Scanner
Analyzes responses and generates custom payloads using LLM intelligence
"""

import json
import re
import asyncio
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import aiohttp
import logging
from ..core.base_component import BaseComponent

logger = logging.getLogger(__name__)

class VulnType(Enum):
    SQL_INJECTION = "sql_injection"
    XSS = "xss"
    COMMAND_INJECTION = "command_injection"
    PATH_TRAVERSAL = "path_traversal"
    XXE = "xxe"
    SSTI = "ssti"
    LDAP_INJECTION = "ldap_injection"
    NOSQL_INJECTION = "nosql_injection"
    DESERIALIZATION = "deserialization"
    LOGIC_FLAW = "logic_flaw"

@dataclass
class VulnAnalysis:
    vuln_type: VulnType
    confidence: float
    payload: str
    explanation: str
    exploitation_steps: List[str]
    impact_assessment: str
    custom_payloads: List[str]

class AIVulnerabilityScanner(BaseComponent):
    """
    AI-powered vulnerability scanner that uses machine learning to:
    1. Analyze HTTP responses for vulnerability indicators
    2. Generate custom payloads based on target technology
    3. Learn from successful/failed attempts
    4. Adapt attack vectors in real-time
    """
    
    def __init__(self, config: Dict):
        super().__init__("AIVulnerabilityScanner", config)
        self.ai_endpoint = config.get('ai_endpoint', 'http://localhost:11434')  # Ollama default
        self.model_name = config.get('model_name', 'llama2')
        self.learning_data = {}
        self.success_patterns = {}
    
    def initialize(self) -> bool:
        """Initialize the AI vulnerability scanner"""
        logger.info("AI Vulnerability Scanner initialized")
        self.is_initialized = True
        return True
        
    def cleanup(self) -> bool:
        """Clean up resources"""
        logger.info("AI Vulnerability Scanner cleanup completed")
        return True
        
    async def analyze_target(self, url: str, response_data: Dict) -> List[VulnAnalysis]:
        """
        AI-powered analysis of target responses to identify vulnerabilities
        """
        try:
            # Extract technology stack
            tech_stack = await self._identify_technology_stack(response_data)
            
            # Generate AI prompt for vulnerability analysis
            analysis_prompt = self._create_analysis_prompt(url, response_data, tech_stack)
            
            # Query AI model
            ai_response = await self._query_ai_model(analysis_prompt)
            
            # Parse AI response into structured vulnerability data
            vulnerabilities = await self._parse_ai_analysis(ai_response, tech_stack)
            
            # Generate custom payloads for each vulnerability
            for vuln in vulnerabilities:
                vuln.custom_payloads = await self._generate_custom_payloads(vuln, tech_stack)
            
            return vulnerabilities
            
        except Exception as e:
            logger.error(f"AI analysis failed: {e}")
            return []
    
    async def _identify_technology_stack(self, response_data: Dict) -> Dict[str, str]:
        """
        AI-powered technology stack identification
        """
        headers = response_data.get('headers', {})
        body = response_data.get('body', '')
        
        tech_prompt = f"""
        Analyze the following HTTP response and identify the technology stack:
        
        Headers: {json.dumps(headers, indent=2)}
        Body sample: {body[:1000]}...
        
        Identify:
        1. Web server (Apache, Nginx, IIS, etc.)
        2. Backend language (PHP, Python, Java, .NET, Node.js, etc.)
        3. Framework (Laravel, Django, Spring, Express, etc.)
        4. Database hints (MySQL, PostgreSQL, MongoDB, etc.)
        5. CMS/Platform (WordPress, Drupal, Joomla, etc.)
        
        Return as JSON: {{"server": "", "language": "", "framework": "", "database": "", "cms": ""}}
        """
        
        ai_response = await self._query_ai_model(tech_prompt)
        try:
            return json.loads(ai_response)
        except:
            return {}
    
    def _create_analysis_prompt(self, url: str, response_data: Dict, tech_stack: Dict) -> str:
        """
        Create comprehensive AI prompt for vulnerability analysis
        """
        return f"""
        You are an expert penetration tester analyzing a web application for vulnerabilities.
        
        TARGET: {url}
        TECHNOLOGY STACK: {json.dumps(tech_stack)}
        
        HTTP RESPONSE DATA:
        Status: {response_data.get('status_code', 'Unknown')}
        Headers: {json.dumps(response_data.get('headers', {}), indent=2)}
        Body: {response_data.get('body', '')[:2000]}...
        
        ANALYSIS REQUIRED:
        1. Identify potential vulnerabilities (SQL injection, XSS, command injection, etc.)
        2. Assess confidence level (0.0-1.0) for each vulnerability
        3. Explain the reasoning for each finding
        4. Suggest exploitation techniques specific to the identified technology stack
        5. Estimate potential impact
        
        Focus on:
        - Error messages that reveal internal structure
        - Input reflection patterns
        - Technology-specific vulnerabilities
        - Logic flaws in application behavior
        - Authentication/authorization weaknesses
        
        Return analysis as JSON array:
        [
          {{
            "vuln_type": "sql_injection",
            "confidence": 0.85,
            "explanation": "Error message reveals MySQL syntax",
            "exploitation_steps": ["Step 1", "Step 2"],
            "impact_assessment": "High - Database access possible"
          }}
        ]
        """
    
    async def _query_ai_model(self, prompt: str) -> str:
        """
        Query local AI model (Ollama) for analysis
        """
        try:
            async with aiohttp.ClientSession() as session:
                payload = {
                    "model": self.model_name,
                    "prompt": prompt,
                    "stream": False
                }
                
                async with session.post(f"{self.ai_endpoint}/api/generate", json=payload) as response:
                    if response.status == 200:
                        result = await response.json()
                        return result.get('response', '')
                    else:
                        logger.error(f"AI model query failed: {response.status}")
                        return ""
        except Exception as e:
            logger.error(f"AI model connection failed: {e}")
            return ""
    
    async def _parse_ai_analysis(self, ai_response: str, tech_stack: Dict) -> List[VulnAnalysis]:
        """
        Parse AI response into structured vulnerability objects
        """
        vulnerabilities = []
        
        try:
            # Extract JSON from AI response
            json_match = re.search(r'\[.*\]', ai_response, re.DOTALL)
            if json_match:
                vuln_data = json.loads(json_match.group())
                
                for vuln in vuln_data:
                    if vuln.get('confidence', 0) > 0.3:  # Minimum confidence threshold
                        vulnerabilities.append(VulnAnalysis(
                            vuln_type=VulnType(vuln.get('vuln_type', 'logic_flaw')),
                            confidence=vuln.get('confidence', 0.5),
                            payload="",  # Will be generated separately
                            explanation=vuln.get('explanation', ''),
                            exploitation_steps=vuln.get('exploitation_steps', []),
                            impact_assessment=vuln.get('impact_assessment', ''),
                            custom_payloads=[]
                        ))
        except Exception as e:
            logger.error(f"Failed to parse AI analysis: {e}")
        
        return vulnerabilities
    
    async def _generate_custom_payloads(self, vuln: VulnAnalysis, tech_stack: Dict) -> List[str]:
        """
        Generate custom payloads based on vulnerability type and technology stack
        """
        payload_prompt = f"""
        Generate 5 custom exploit payloads for a {vuln.vuln_type.value} vulnerability.
        
        TARGET TECHNOLOGY:
        - Server: {tech_stack.get('server', 'Unknown')}
        - Language: {tech_stack.get('language', 'Unknown')}
        - Framework: {tech_stack.get('framework', 'Unknown')}
        - Database: {tech_stack.get('database', 'Unknown')}
        
        VULNERABILITY CONTEXT: {vuln.explanation}
        
        Requirements:
        1. Payloads must be specific to the identified technology stack
        2. Include both basic and advanced exploitation techniques
        3. Consider WAF bypass techniques
        4. Include time-based and blind exploitation methods where applicable
        5. Ensure payloads are production-ready, not just theoretical
        
        Return as JSON array of strings: ["payload1", "payload2", ...]
        """
        
        ai_response = await self._query_ai_model(payload_prompt)
        
        try:
            json_match = re.search(r'\[.*\]', ai_response, re.DOTALL)
            if json_match:
                return json.loads(json_match.group())
        except:
            pass
        
        # Fallback to basic payloads if AI fails
        return self._get_fallback_payloads(vuln.vuln_type)
    
    def _get_fallback_payloads(self, vuln_type: VulnType) -> List[str]:
        """
        Fallback payloads when AI generation fails
        """
        fallback_payloads = {
            VulnType.SQL_INJECTION: [
                "' OR '1'='1",
                "'; DROP TABLE users; --",
                "' UNION SELECT 1,2,3,4,5 --",
                "' AND (SELECT COUNT(*) FROM information_schema.tables)>0 --"
            ],
            VulnType.XSS: [
                "<script>alert('XSS')</script>",
                "<img src=x onerror=alert('XSS')>",
                "javascript:alert('XSS')",
                "<svg onload=alert('XSS')>"
            ],
            VulnType.COMMAND_INJECTION: [
                "; ls -la",
                "| whoami",
                "`id`",
                "&& cat /etc/passwd"
            ]
        }
        
        return fallback_payloads.get(vuln_type, ["test_payload"])
    
    async def learn_from_attempt(self, payload: str, success: bool, response_data: Dict):
        """
        Machine learning component - learn from successful/failed attempts
        """
        if success:
            # Store successful patterns for future use
            pattern_key = self._extract_pattern(payload)
            if pattern_key not in self.success_patterns:
                self.success_patterns[pattern_key] = []
            self.success_patterns[pattern_key].append({
                'payload': payload,
                'response': response_data,
                'timestamp': asyncio.get_event_loop().time()
            })
        
        # Update learning data
        self.learning_data[payload] = {
            'success': success,
            'response': response_data,
            'attempts': self.learning_data.get(payload, {}).get('attempts', 0) + 1
        }
    
    def _extract_pattern(self, payload: str) -> str:
        """
        Extract pattern from successful payload for learning
        """
        # Simple pattern extraction - could be enhanced with ML
        if "UNION SELECT" in payload.upper():
            return "union_based_sqli"
        elif "<script>" in payload.lower():
            return "script_based_xss"
        elif ";" in payload and ("ls" in payload or "cat" in payload):
            return "command_injection"
        else:
            return "unknown_pattern"
    
    async def get_adaptive_payloads(self, vuln_type: VulnType, target_info: Dict) -> List[str]:
        """
        Generate adaptive payloads based on learning data
        """
        # Use learning data to improve payload generation
        successful_patterns = [
            pattern for pattern, data in self.success_patterns.items()
            if any(attempt['success'] for attempt in data)
        ]
        
        # Generate new payloads based on successful patterns
        if successful_patterns:
            adaptation_prompt = f"""
            Generate new {vuln_type.value} payloads based on these successful patterns:
            {json.dumps(successful_patterns)}
            
            Target info: {json.dumps(target_info)}
            
            Create 3 new payloads that combine successful elements with new techniques.
            Return as JSON array.
            """
            
            ai_response = await self._query_ai_model(adaptation_prompt)
            try:
                json_match = re.search(r'\[.*\]', ai_response, re.DOTALL)
                if json_match:
                    return json.loads(json_match.group())
            except:
                pass
        
        return self._get_fallback_payloads(vuln_type)

# Factory function
def create_ai_vulnerability_scanner(config: Dict) -> AIVulnerabilityScanner:
    """
    Factory function to create AI vulnerability scanner
    """
    return AIVulnerabilityScanner(config)
